{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gmplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e232b8fa6e79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgmplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gmplot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gmplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"housing.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bedrooms'].fillna(df['total_bedrooms'].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see total bedrooms has a very low correlation with median income so we just impute the mean to fill nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bedrooms'].fillna(df['total_bedrooms'].mean,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = df[\"latitude\"]\n",
    "longitudes = df[\"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap = gmplot.GoogleMapPlotter(37.88, -122.23, 10)\n",
    "gmap.heatmap(latitudes, longitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap.draw(\"my_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(df['median_house_value'],color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the distribution of our target variable to right skewed and not normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(df['median_house_value'],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df['median_house_value'], rug=True, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "ax = sns.distplot(df['median_house_value'], fit=norm, kde=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we can see what the Hernel density estimation would look like on a normal distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"longitude\", y=\"latitude\",hue=\"median_house_value\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='longitude', y='latitude', alpha=0.9, \n",
    "    s=df['population']/10, label='population', figsize=(14,10), \n",
    "    c='median_house_value', cmap=plt.get_cmap('cool'), colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"ocean_proximity\"])[\"median_house_value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = df.pivot_table(values='median_house_value',index=['ocean_proximity'])\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see from the groups and data inland houses seem to have a much lover mean and medium house value suggesting the closer to the coast a block of houses are the higher the medium value and islands seem to contain outlier values, ocean proximity could possibly be a useful feature in predicting the house value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"ocean_proximity\"] != \"ISLAND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='median_income', y='median_house_value', alpha=0.2, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we see serval large horixonal lines in the scatter the largest of which is 500000 we will remove rows with 500000 to balalance the distribution a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"median_house_value\"] < 499000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='median_income', y='median_house_value', alpha=0.2, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is opnly 5 island districts and they are large outlier value we will remove islands from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rooms_per_household'] = df['total_rooms']/df['households']\n",
    "df['bedrooms_per_room'] = df['total_bedrooms']/df['total_rooms']\n",
    "\n",
    "# checkout the correlations again\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "some interesting data created bedroom per room having the third best corrolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(df['median_house_value'],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removed the major outlier from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=df.iloc[:,0:7].values\n",
    "y = df.iloc[:,8].values\n",
    "#print(df.iloc[:,8])\n",
    "#df = df.drop([\"median_house_value\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "#le.fit(df[\"ocean_proximity\"])\n",
    "#le.classes_\n",
    "df[\"ocean_proximity\"] = le.fit_transform(df[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics\n",
    "\n",
    "#Generic function for making a classification model and accessing performance:\n",
    "def classification_model(model, data, predictors, outcome):\n",
    "  #Fit the model:\n",
    "  model.fit(data[predictors],data[outcome])\n",
    "  \n",
    "  #Make predictions on training set:\n",
    "  predictions = model.predict(data[predictors])\n",
    "  \n",
    "\n",
    "  #Perform k-fold cross-validation with 10 folds\n",
    "  kf = KFold(data.shape[0], n_folds=10)\n",
    "  error = []\n",
    "  for train, test in kf:\n",
    "    # Filter training data\n",
    "    train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = data[outcome].iloc[train]\n",
    "    \n",
    "    # Training the algorithm using the predictors and target.\n",
    "    model.fit(train_predictors, train_target)\n",
    "    \n",
    "    #Record error from each cross-validation run\n",
    "    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    " \n",
    "  print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "  #Fit the model again so that it can be refered outside the function:\n",
    "  model.fit(data[predictors],data[outcome]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "#outcome_var = 'median_house_value'\n",
    "#predictor_var = ['ocean_proximity','rooms_per_household','median_income']\n",
    "#model = LinearRegression()\n",
    "#classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = linear_regressor.predict(xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = linear_regressor.predict(xtest)\n",
    "lin_mse = mean_squared_error(ytest,predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('rmse value is : ',lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_score = linear_regressor.score(xtest,ytest)\n",
    "print('r squared value is : ',lin_reg_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_regressor = DecisionTreeRegressor(random_state=0)\n",
    "tree_regressor.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_regressor.predict(xtest)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_score = tree_regressor.score(xtest,ytest)\n",
    "print('r squared value is : ',tree_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "outcome_var = 'median_house_value'\n",
    "predictor_var = ['ocean_proximity','rooms_per_household','median_income']\n",
    "model = LinearRegression()\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_copy = df.drop([\"median_house_value\"], axis=1)\n",
    "scaler = StandardScaler()\n",
    "tree_regressor = DecisionTreeRegressor(random_state=0)\n",
    "model = RandomForestClassifier(n_estimators=25, min_samples_split=10, max_depth=7, max_features=1)\n",
    "#predictor_var = ['wage-increase-first-year','statutory-holidays','wage-increase-second-year',\n",
    "                 #'working-hours']\n",
    "#classification_model(model, df,predictor_var,outcome_var)\n",
    "\n",
    "#print(scaler.fit(df_copy))\n",
    "y = df[\"median_house_value\"].values\n",
    "x = scaler.fit_transform(df_copy)\n",
    "#print(x[:])\n",
    "model.fit(x, y)\n",
    "model.score(x,y)\n",
    "kf = KFold(x.shape[0], n_folds=10)\n",
    "error = []\n",
    "error1 = []\n",
    "for train, test in kf:\n",
    "    model.fit(x[train], y[train])\n",
    "    error.append(model.score(x[test], y[test]))\n",
    "    tree_regressor.fit(x[train], y[train])\n",
    "    error1.append(tree_regressor.score(x[test], y[test]))\n",
    "    #print(x[train])\n",
    "    #tree_regressor.fit(x[train],y[train])\n",
    "    #ypred = linear_regressor.predict(x[test])\n",
    "    #lin_mse = mean_squared_error(ytest,predictions)\n",
    "    #lin_rmse = np.sqrt(lin_mse)\n",
    "    #print('rmse value is : ',lin_rmse)\n",
    "    \n",
    "print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#labelencoder = LabelEncoder()\n",
    "#print(x[:, 9])\n",
    "#x[:, 8] = labelencoder.fit_transform(x[:, 8])\n",
    "#onehotencoder = OneHotEncoder(categorical_features = [8])\n",
    "#x = onehotencoder.fit_transform(x).toarray()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaler.fit_transform(df[[\"housing_median_age\",\"ocean_proximity\",\"median_income\",\"bedrooms_per_room\",\n",
    "                          \"population\",\"rooms_per_household\"]].values)\n",
    "print(x)\n",
    "\n",
    "y=df['median_house_value'].values\n",
    "print(y)\n",
    "\n",
    "model = LinearRegression()\n",
    "kf = KFold(x.shape[0], n_folds=10)\n",
    "error = []\n",
    "\n",
    "for train, test in kf:\n",
    "    model.fit(x[train], y[train])\n",
    "    error.append(model.score(x[test], y[test]))\n",
    "    print(y[test])\n",
    "    print(model.predict(x[test]))\n",
    "print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
